# -*- coding: utf-8 -*-
"""Credit  Approval.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iOfdzkJMuMKxiIubuXjpGJcm407GGZRR

# **Library**
"""

import pandas as pd
from matplotlib import pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.impute import KNNImputer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from time import time
from sklearn.metrics import classification_report

df = pd.read_csv (r'/content/crx.csv', header=None, na_values=['N/A', '?', 'xx', 'missing','x'])

df

"""# **Exploring**"""

df.isna().sum()

df.info()

df.describe()

"""# **Quantitative data**"""

sns.set_theme()

fig, axes = plt.subplots(1, 2)
fig.suptitle('(Comparison between skewed data and log transform effect on skewness)')
axes[0].set_title('native feature')
sns.histplot(ax = axes[0], x=df[1])
axes[1].set_title('Log transform')
sns.histplot(ax = axes[1], x=np.log(df[1]))

fig, axes = plt.subplots(1, 2, sharey=True)
sns.boxplot(ax= axes[0], y=df[1], x=df[15])
sns.boxplot(ax= axes[1], y=df[1])

fig, axes = plt.subplots(1, 2, sharey=True)
sns.boxplot(ax= axes[0], y=df[2], x=df[15])
sns.boxplot(ax= axes[1], y=df[2])

fig, axes = plt.subplots(1, 2)
fig.suptitle('(Comparison between skewed data and log transform effect on skewness)')
axes[0].set_title('native feature')
sns.histplot(ax = axes[0], x=df[7])
axes[1].set_title('Log transform')
sns.histplot(ax = axes[1], x=np.log(df[7]))

fig, axes = plt.subplots(1, 2, sharey=True)
sns.boxplot(ax= axes[0], y=df[7], x=df[15])
sns.boxplot(ax= axes[1], y=df[7])

fig, axes = plt.subplots(1, 2)
fig.suptitle('(Comparison between skewed data and log transform effect on skewness)')
axes[0].set_title('native feature')
sns.histplot(ax = axes[0], x=df[10])
axes[1].set_title('Log transform')
sns.histplot(ax = axes[1], x=np.log(df[10]))

fig, axes = plt.subplots(1, 2, sharey=True)
sns.boxplot(ax= axes[0], y=df[10], x=df[15])
sns.boxplot(ax= axes[1], y=df[10])

fig, axes = plt.subplots(1, 3, sharey=False)
axes[0].set_title('Total')
sns.histplot(ax= axes[0], x=df[10])
axes[1].set_title('feature 10, pos')
sns.histplot(ax= axes[1], x=df.loc[df[15] == '+', 10])
axes[2].set_title('feature 10, neg')
sns.histplot(ax= axes[2], x=df.loc[df[15] == '-', 10])
fig.tight_layout()

fig, axes = plt.subplots(1, 2)
fig.suptitle('(Comparison between skewed data and log transform effect on skewness)')
axes[0].set_title('native feature')
sns.histplot(ax = axes[0], x=df[13])
axes[1].set_title('Log transform')
sns.histplot(ax = axes[1], x=np.log(df[13]))

fig, axes = plt.subplots(1, 2, sharey=True)
sns.boxplot(ax= axes[0], y=df[13], x=df[15])
sns.boxplot(ax= axes[1], y=df[13])

fig, axes = plt.subplots(1, 2)
fig.suptitle('(Comparison between skewed data and log transform effect on skewness)')
axes[0].set_title('native feature')
sns.histplot(ax = axes[0], x=df[14])
axes[1].set_title('Log transform')
sns.histplot(ax = axes[1], x=np.log(df[14]))

fig, axes = plt.subplots(1, 2, sharey=True)
sns.boxplot(ax= axes[0], y=df[14], x=df[15])
sns.boxplot(ax= axes[1], y=df[14])

df.corr()

"""# **Qualitative data**"""

df[0].value_counts()

CrosstabResult=pd.crosstab(index=df[0],columns=df[15])
CrosstabResult.plot.bar()

df[3].value_counts()

CrosstabResult=pd.crosstab(index=df[3],columns=df[15])
CrosstabResult.plot.bar()

df[4].value_counts()

CrosstabResult=pd.crosstab(index=df[4],columns=df[15])
CrosstabResult.plot.bar()

df[5].value_counts()

CrosstabResult=pd.crosstab(index=df[5],columns=df[15])
CrosstabResult.plot.bar()

df[6].value_counts()

CrosstabResult=pd.crosstab(index=df[6],columns=df[15])
CrosstabResult.plot.bar()

df[8].value_counts()

CrosstabResult=pd.crosstab(index=df[8],columns=df[15])
CrosstabResult.plot.bar()

df[9].value_counts()

CrosstabResult=pd.crosstab(index=df[9],columns=df[15])
CrosstabResult.plot.bar()

df[11].value_counts()

CrosstabResult=pd.crosstab(index=df[11],columns=df[15])
CrosstabResult.plot.bar()

df[12].value_counts()

CrosstabResult=pd.crosstab(index=df[12],columns=df[15])
CrosstabResult.plot.bar()

"""# **Cont. features**"""

CONT_FEATURES = [1,	2,	7,	10, 13, 14]

df[CONT_FEATURES]

df_log_cont = df.apply(lambda x: np.log(x + np.finfo(float).eps) if x.name in CONT_FEATURES else x)

df_log_cont

"""# **Disc. features**"""

DISC_FEATURES = [0, 3, 4, 5, 6, 8, 9, 11, 12]
BINARY_DISC_FEATURES = [0, 8, 9, 11]
label = 15

df_dic_only = pd.get_dummies(df_log_cont.loc[:, DISC_FEATURES], dummy_na=True)

df_dic_only

nan_df = df_dic_only.loc[:, df_dic_only.columns.str.endswith("_nan")]

nan_df

for index in df_dic_only.index:
    for col_nan in nan_df.columns:
        if df_dic_only.loc[index,col_nan] == 1:
            col_id = col_nan.split('_')[0]
            targets = df_dic_only.columns[df_dic_only.columns.str.startswith(col_id+'_')]
            df_dic_only.loc[index, targets] = np.nan

df_dic_only.info()

df_dic_only.drop(df_dic_only.columns[df_dic_only.columns.str.endswith('_nan')], axis=1, inplace=True)

df_dic_only.info()

df_log_cont

df_log_cont = pd.concat([df_log_cont, df_dic_only], axis=1)

df_log_cont

df_log_cont = pd.concat([df_log_cont, pd.get_dummies(df_log_cont[15]).iloc[:,0]], axis=1)

df_log_cont

df_log_cont.drop(DISC_FEATURES, axis=1, inplace=True)

df_log_cont.drop(15, axis=1, inplace=True)

df_log_cont

df_log_cont.info()

"""# **Impute the nan values**"""

imputer = KNNImputer(n_neighbors=5)

df_log_cont = imputer.fit_transform(df_log_cont)

df_log_cont.shape

"""# **Split the data**"""

X_train, X_test, y_train, y_test = train_test_split(df_log_cont[:,:-1], df_log_cont[:,-1], test_size=0.2, stratify=df_log_cont[:,-1], random_state=17)

X_train.shape, X_test.shape

"""# **Normalization**"""

scalar = RobustScaler()

X_train = scalar.fit_transform(X_train)

X_test = scalar.transform(X_test)

"""# **Model**"""

param_dist = {'n_estimators': np.arange(3, 20),
              'max_depth': np.arange(2, 20),
              'min_samples_split': np.arange(2, 20)}

model = RandomForestClassifier(random_state=17)

n_iter_search = 100
random_search = RandomizedSearchCV(model, param_distributions=param_dist,
                                   n_iter=n_iter_search, scoring='accuracy', random_state=17)

def report(results, n_top=6):
    for i in range(1, n_top + 1):
        candidates = np.flatnonzero(results['rank_test_score'] == i)
        for candidate in candidates:
            print("Model with rank: {0}".format(i))
            print("Mean validation score: {0:.3f} (std: {1:.3f})"
                  .format(results['mean_test_score'][candidate],
                          results['std_test_score'][candidate]))
            print("Parameters: {0}".format(results['params'][candidate]))
            print("")

start = time()
random_search.fit(X_train, y_train)
print("RandomizedSearchCV took %.2f seconds for %d candidates"
      " parameter settings." % ((time() - start), n_iter_search))
report(random_search.cv_results_)

model_best = RandomForestClassifier(n_estimators= 17, min_samples_split= 15, max_depth= 13, random_state=17)

model_best.fit(X_train, y_train)

"""# **Model evaluation**"""

def compute_classification_report(y_true, y_pred):
  target_names = ['No', 'Yes']
  print(classification_report(y_true, y_pred, target_names=target_names, digits=4))

y_pred_train = model_best.predict(X_train)
y_pred_test = model_best.predict(X_test)

compute_classification_report(y_train, y_pred_train)

compute_classification_report(y_test, y_pred_test)

